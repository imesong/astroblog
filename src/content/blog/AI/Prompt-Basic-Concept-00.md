---
title: prompt-basic-concept
author: imesong
pubDatetime: 2024-07-08
modDatetime: 2024-07-08
slug: prompt-basic-concept-00
featured: false
draft: true
tags:
  - AI101
  - prompt
description: 理解 prompt 的本质，使用通熟易懂的语言解释什么是 prompt。透过 prompt 本质，研究prompt的演化趋势。 文章内容是个人学习的主观总结，为对内容的真实性和准确性验证，请大家酌情理解。
---

---

> 文章内容是个人学习的主观总结，无法保证内容的真实性和准确性，请大家酌情理解。

## LLM 的不可知性

按照我现在的理解，LLM 的内部系统还是个黑盒，我们不知道准确的原因，为啥系统会给我们这样的输出。不可知不代表不能用，我们不知道发动机的驱动原理，但掌握了驾驶汽车的技巧，还是可以自由的驾车远行。我们不知道手机信号的发射和接收原理，但掌握手机上应用程序的使用方法，就可以顺利的拨打和接听电话。在*实用主义* 的角度说，先跑起来，能用就行。如果刚开始就一头扎进去研究底层的理论和算法，就会陷入系统的汪洋之中迷失方法，最终走马观花一样，啥都了解一些，但都不深入。

所以，不了解 LLM 的底层原理和内部的运作机制，并不妨碍成为一个 Prompt 高手。

假如，LLM 系统是哆啦 A 梦的宝库，prompt 就是开启宝库的指令，我们需要告诉 LLM，我们的愿望是什么，希望它帮我们干什么。

不同版本的 LLM，对人类给他的 prompt 理解程度不一样。聪明一点的，我们给出的 prompt 即使有错误，有一些别字和错字，他也能准确的推测出我们想表达的含义。

有的 LLM 记忆只有几秒钟，经过几轮对话，它就忘记了自己是谁，在干啥事情。需要人类不断的提示它，它现在要干嘛，怎么干，要求是什么。就像一个幼儿园的小朋友，经常跑神。

有的 LLM，经常搞错自己的角色，如果男人有一千面孔，那 LLM 的面孔要比中关村的男人面孔加起来还多。它有时会搞错自己应该扮演的角色，原本是在公司开会，记录会议纪要，突然觉得自己是一个小说写作专家，自己根据会议主题对会议纪要自由发挥了。在开家长会给小朋友写评语时，变成了互联网公司的 PUA 专家，把其他家的小朋友整的童年都失去了颜色。

这些都是我们现在已知的，非常明显的 LLM 的问题。我相信，随着 LLM 版本的迭代升级，也许到 ChatGPT5 时能解决。这些问题，我们通过优化 prompt 能够解决其中的大部分。要时等到所有问题都解决了，我们再想参与这次的 AI 浪潮，会发现不只是海里，沙滩上都挤满了人，下脚的地方都没有了。

## Prompt 的几个原则

网上有这样一个段子，关于程序员小王和他老婆的故事。

> 家里的菜不多了，程序员的老婆叫小王去买菜，说：“你去买三斤土豆吧，家里的土豆没有了；如果看到卖西瓜的，就买一个。”
> 小王收到指示，麻溜溜的就骑着电驴去买菜了，在路过水果店的时候，小王看到了卖西瓜的，然后去买土豆时，小王就买了一个土豆🥔，特意挑选了一个大的。
> 小王回到家，给他老婆说，“我回来了，看见了卖西瓜的，就买了一个土豆”。小王的媳妇儿听完，肺都气炸了。

关注公众号 **技术后花园** 获取更多信息

![image.png](https://img.imesong.com/file/9e0dc4dc2d2acd363d535.png)
